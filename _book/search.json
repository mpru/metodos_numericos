[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Métodos Numéricos con Python",
    "section": "",
    "text": "Prefacio\nEl presente documento es la guía de estudio para la asignatura Métodos Numéricos de la Licenciatura en Estadística (Universidad Nacional de Rosario). Se ha utilizado como fuente para la creación de este material a la bibliografía mencionada en el programa de la asignatura. La asignatura se complementa con variados materiales (prácticas, ejemplos, proyectos) disponibles en el aula virtual del curso de acceso privado.\nEstos apuntes no están libres de contener errores. Sugerencias para corregirlos o para expresar de manera más adecuada las ideas volcadas son siempre bienvenidas1.\nPrimera publicación: enero 2024.\n\n\n\n\n\n\nEn general, no se cuenta con derechos para las imágenes empleadas (a menos que sean de creación propia). Ante cualquier problema, contactar al autor.↩︎",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "02_ecuaciones.html#introducción",
    "href": "02_ecuaciones.html#introducción",
    "title": "1  Resolución de ecuaciones en una variable",
    "section": "1.1 Introducción",
    "text": "1.1 Introducción\n\nEn esta unidad consideraremos uno de los problemas más básicos de la aproximación numérica: el problema de la búsqueda de la raíz, es decir, encontrar una raíz o solución para una ecuación de la forma \\(f(x) = 0\\), para una función \\(f\\) dada.\nUna raíz de esta ecuación también recibe el nombre de cero de la función \\(f\\).\nGeneralmente se clasifica a las ecuaciones como lineales o no lineales\n\nUna ecuación lineal es una igualdad que involucra una o más variables elevadas a la primera potencia y no contiene productos entre las variables (involucra solamente sumas y restas de las variables). Por ejemplo: \\(3x+2 = 8\\).\nPara este tipo de ecuaciones es posible hallar analíticamente una expresión para su solución, aunque esto puede resultar en un proceso complejo.\nEn una ecuación no lineal las incógnitas están elevadas a potencias distintas de \\(1\\), aparecen en denominadores o exponentes o están afectadas por funciones no lineales (como el logaritmo o las trigonométricas).\n\nA las ecuaciones no lineales se las suele clasificar como:\n\nEcuaciones algebraicas: involucran un polinomio igualado a cero:\n\\[\nP_n(x) = a_0 x^n + a_1 x^{n-1} + ... + a_{n-1} x + a_n = 0\n\\]\ndonde \\(a_0 \\ne 0, n \\in \\mathbb{N}\\) y \\(a_0, \\dots, a_n\\) son constantes.\nPor ejemplo: \\(x^3 - x^2 + 5x - 8 = 2x^5\\).\nSabemos que si, por ejemplo, \\(n = 2\\), la solución de \\(ax^2 + b x + c = 0\\) está dada por la resolvente:\n\\[\nx_{1,2} = \\frac{b \\pm \\sqrt{b^2 - 4ac}}{2a}\n\\]\nSin embargo, la solución análitica para este tipo de ecuaciones existe sólo para \\(n \\le 4\\).\nEcuaciones trascendentes: incluyen a los otros tipos de ecuaciones no lineales, como por ejemplo:\n\\[\\begin{gather*}\nx^3 - ln (x) + \\frac{3}{x} = 2 \\\\\ntg(x + 45) = 1 + sen(2x) \\\\\nxe^{x}=1 \\\\\n{\\displaystyle 5^{x}=9^{x+1} 3^{x}}\n\\end{gather*}\\]\nEn general, tampoco es posible hallar de manera analítica una solución exacta para estas ecuaciones.\n\nEstudiaremos distintos métodos para encontrar las soluciones aproximadas a ecuaciones de una variable, ya sean estas lineales o no lineales.\nTodos los métodos que desarrollaremos tienen en común el empleo de una técnica fundamental para el análisis numérico: la iteración.\nLos métodos iterativos repiten un proceso hasta obtener un resultado para el problema.\nAplicados a la búsqueda de raíces, en general estos métodos requieren de dos pasos generales:\n\nDeterminar un valor aproximado de la raíz que se busca.\nMejorar la solución hasta lograr un grado de precisión preestablecido.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Resolución de ecuaciones en una variable</span>"
    ]
  },
  {
    "objectID": "02_ecuaciones.html#el-método-de-la-bisección-o-búsqueda-binaria",
    "href": "02_ecuaciones.html#el-método-de-la-bisección-o-búsqueda-binaria",
    "title": "1  Resolución de ecuaciones en una variable",
    "section": "1.2 El método de la bisección o búsqueda binaria",
    "text": "1.2 El método de la bisección o búsqueda binaria\n\nSe basa en el teorema de Bolzano1, que dice que si \\(f\\) es una función continua definida dentro del intervalo \\([a, b]\\) con \\(f(a)\\) y \\(f(b)\\) de signos opuestos, entonces existe un número \\(p\\) en \\((a, b)\\) con \\(f(p) = 0\\) (es decir, \\(p\\) es la solución de la ecuación \\(f(x) = 0\\)).\nEl método realiza repetidamente una reducción a la mitad (o bisección) de subintervalos de \\([a, b]\\), localizando en cada paso la mitad que contiene a \\(p\\):\n\n\n\n\n\n\n\nPara comenzar, sea \\(a_1 = a\\), \\(b_1 = b\\) y \\(p_1 = \\frac{a_1 + b_1}{2}\\) el punto medio de \\([a, b]\\).\nSi \\(f(p_1) = 0\\), entonces \\(p= p_1\\) y terminamos (ya encontramos la raíz).\nSi \\(f(p_1) \\neq 0\\):\n\nSi \\(f(a_1)\\) y \\(f(p_1)\\) tienen el mismo signo, \\(p \\in (p_1, b_1)\\). Se define el nuevo subintervalo como \\(a_2 = p_1\\) y \\(b_2 = b_1\\).\nSi \\(f(a_1)\\) y \\(f(p_1)\\) tienen signos opuestos, \\(p \\in (a_1, p_1)\\). Se define el nuevo subintervalo como \\(a_2 = a_1\\) y \\(b_2 = p_1\\).\n\nSe vuelve a aplicar el proceso al intervalo \\([a_2, b_2]\\) y así sucesivamente hasta verificar algún criterio de parada.\nPor ejemplo, podemos seleccionar una tolerancia \\(\\epsilon &gt; 0\\) y detener el proceso siguiendo alguna de estas opciones:\n\nCuando la semiamplitud del intervalo sea muy pequeña:\n\n\\[\n  \\frac{b-a}{2} &lt; \\epsilon\n  \\]\n\nCuando el valor de la función evaluado en \\(f(p_n)\\) sea muy pequeño (esto implica que \\(p_n\\) está próximo a la raíz):\n\n\\[\n  |f(p_n)| &lt; \\epsilon\n  \\]\n\nCuando la diferencia absoluta o relativa entre dos aproximaciones sucesivas sea muy pequeña:\n\n\\[\n  |p_n - p_{n-1}| &lt; \\epsilon\n  \\]\n\\[\n  \\frac{|p_n - p_{n-1}|}{|p_n|} &lt; \\epsilon, \\quad p_N \\neq 0\n  \\]\nEstas última serán empleadas en muchos métodos iterativos que estudiaremos, optando generalmente por la que se basa en la diferencia relativa.\nEn los métodos iterativos es importante establecer un límite superior sobre el número de iteraciones, para eliminar la posibilidad de entrar en un ciclo infinito (puede ocurrir si la sucesión diverge o si el programa está codificado incorrectamente). El método de la bisección no diverge pero aún así es recomendable establecer esta cota superior para la cantidad de iteraciones.\nDesventajas:\n\nConvergencia lenta (\\(n\\) puede volverse bastante grande antes de que \\(|p-p_n|\\) sea suficientemente pequeño).\nSe podría descartar inadvertidamente una buena aproximación intermedia.\n\nVentajas:\n\nConceptualmente claro.\nSiempre converge a una solución.\n\nPor las características anteriores, con frecuencia se utiliza este método como punto de partida para otros métodos más eficientes.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Resolución de ecuaciones en una variable</span>"
    ]
  },
  {
    "objectID": "02_ecuaciones.html#el-método-del-punto-fijo-o-de-las-aproximaciones-sucesivas",
    "href": "02_ecuaciones.html#el-método-del-punto-fijo-o-de-las-aproximaciones-sucesivas",
    "title": "1  Resolución de ecuaciones en una variable",
    "section": "1.3 El método del punto fijo o de las aproximaciones sucesivas",
    "text": "1.3 El método del punto fijo o de las aproximaciones sucesivas\n\n1.3.1 Punto fijo\n\nUn punto fijo para una función es un número en el que el valor de la función no cambia cuando se aplica la función.\n\n\nDefinición: el número \\(p\\) es un punto fijo para una función dada \\(g\\) si \\(g(p) = p\\).\n\n\nEjemplos:\n\n\\(g(x)=x^{2}-3x+4\\): \\(2\\) es un punto fijo de \\(g\\) porque \\(g(2) = 2\\).\n\\(g(x)=x^{2}\\): \\(0\\) y \\(1\\) son puntos fijos de \\(g\\) porque \\(g(0) = 0\\) y \\(g(1) = 1\\).\n\nEl problema de encontrar la raíz \\(p\\) de una ecuación \\(f(x) = 0\\) puede ser planteado de forma equivalente como la búsqueda del punto fijo de alguna función \\(g(x)\\).\nAntes de ver cómo es eso, tenemos que saber cuándo una función tiene un punto fijo y cómo aproximarlo.\n\n\n1.3.1.1 Interpretación gráfica\n\nDado que un punto fijo es el valor de \\(x\\) que satisface \\(x = g(x)\\), un punto fijo para \\(g\\) ocurre precisamente cuando la gráfica de \\(y = g(x)\\) interseca la gráfica de \\(y=x\\) (recta identidad).\nPor ejemplo, vamos a encontrar los puntos fijos de la función \\(g(x) = x^2 - 2\\). Si graficamos esta curva junto con la recta identidad, encontraremos los puntos fijos de \\(g\\) allí donde ambas se cruzan:\n\n\n\n\n\n\n\nEn la figura podemos observar que los puntos fijos son \\(-1\\) y \\(2\\). De hecho: \\(g(-1) = 1 - 2 = -1\\) y \\(g(2) = 4 - 2 = 2\\).\n\n\n\n1.3.1.2 Cómo encontrar un punto fijo\n\nPara aproximar el punto fijo de una función \\(g\\), elegimos una aproximación inicial \\(p_0\\) y generamos la sucesión \\(\\{p_n\\}_{n=0}^\\infty\\) al permitir \\(p_n = g(p_{n-1})\\) para cada \\(n \\geq 1\\):\n\\[\\begin{gather*}\np_0 \\\\\np_1 = g(p_0) \\\\\np_2 = g(p_1) \\\\\n\\vdots \\\\\np_n = g(p_{n-1}) \\\\\n\\vdots \\\\\n\\end{gather*}\\]\nSi \\(g\\) es continua y la sucesión converge a un número \\(p\\), entonces éste es el punto fijo de \\(g\\). Demostración:\n\nLa sucesión converge a \\(p \\implies p = \\lim_{n \\rightarrow \\infty} p_n\\).\nPor otro lado, \\(\\lim_{n \\rightarrow \\infty} p_n= \\lim_{n \\rightarrow \\infty} g(p_{n-1}) = g\\big( \\lim_{n \\rightarrow \\infty} p_{n-1} \\big) = g(p)\\).\nDe los dos ítems anteriores, resulta que \\(p = g(p)\\), con lo cual \\(p\\) es un punto fijo de \\(g\\).\n\nEsta técnica se conoce como iteración de punto fijo o iteración funcional.\nEjemplos:\n\n\n\n\n\n\n\n\n1.3.1.3 Teorema de punto fijo\n\nNo todas las funciones tienen un punto fijo y aunque lo tengan no siempre la sucesión anterior nos conduce al mismo.\nEl siguiente teorema proporciona condiciones suficientes para garantizar la existencia y unicidad de un punto fijo y para que la sucesión converja al mismo.\n\n\nTeorema de punto fijo:\n\nSi \\(g\\) es continua en \\([a, b]\\) y \\(g(x) \\in [a, b]\\) para todo \\(x \\in [a, b]\\), entonces \\(g\\) tiene por lo menos un punto fjo en \\([a, b]\\).\nSi, además, \\(g'(x)\\) existe en \\((a, b)\\) y existe una constante \\(0&lt;k&lt;1\\) con\n\\[\n|g'(x)| \\leq k \\quad \\forall x \\in (a,b),\n\\]\nentonces existe exactamente un punto fijo \\(p\\) en \\([a, b]\\) y para cualquier número \\(p_0\\) en \\([a, b]\\), la sucesión definida por:\n\\[\np_n = g(p_{n-1}), \\qquad n \\geq 1\n\\]\nconverge al único punto \\(p\\) en \\([a, b]\\).\n\n\n\nLa siguiente imagen ejemplifica la primera condición establecida por el teorema:\n\n\n\n\n\n\n\nEstas condiciones son suficientes pero no necesarias (la función puede tener un único punto fijo aunque no se cumplan).\n\n\n\n\n1.3.2 Uso de la iteración de punto fijo para resolver ecuaciones\n\nSea la ecuación a resolver:\n\\[f(x) = 0\\]\nSiempre es posible reexpresarla en la forma:\n\\[\nx = g(x)\n\\]\ncon alguna función \\(g\\).\nEsto se logra despejando alguna \\(x\\) o, por ejemplo, sumando \\(x\\) a cada miembro de la ecuación:\n\\[\n\\begin{aligned}\n0 &= f(x) \\\\\nx + 0 &= x + f(x) \\\\\nx &= \\underbrace{x + f(x)}_{g(x)}\n\\end{aligned}\n\\]\nLlamemos con \\(p\\) a la solución de la ecuación, es decir, al valor que satisface \\(f(x) = 0\\).\nSi \\(p\\) satisface \\(f(x) = 0\\), entonces también satisface \\(x = g(x)\\) (puesto que es la misma ecuación escrita de otra forma).\nEntonces, la raíz buscada es el punto fijo de \\(g\\).\nAsí, el método de iteración de punto fijo o de aproximaciones sucesivas para resolver \\(f(x) = 0\\) consiste en:\n\nExpresar la ecuación en la forma \\(x = g(x)\\).\nElegir un valor inicial adecuado \\(p_0\\).\nRealizar el siguiente cálculo iterativo:\n\n\\[\\begin{gather*}\n  p_0 \\\\\n  p_1 = g(p_0) \\\\\n  p_2 = g(p_1) \\\\\n  \\vdots \\\\\n  p_n = g(p_{n-1}) \\\\\n  \\vdots \\\\\n  \\end{gather*}\\]\nSi a medida que \\(n\\) crece los \\(p_n\\) se aproximan a un valor fijo, se dice que el método converge y la iteración se detiene cuando la diferencia entre dos valores consecutivos \\(p_{n-1}\\) y \\(p_n\\) sea tan pequeña como se desee, a juzgar por los criterios de parada mencionados anteriormente.\nEl valor \\(p_n\\) será una raíz aproximada de \\(f(x)\\).\n\n\n\n1.3.3 Ejemplo\n\nHallar las raíces de la ecuación no lineal: \\(f(x) = x^2-3x+e^x-2=0\\)\nGraficamos y vemos que las raíces están cercanas a -0.4 y 1.4 (podés hacer estos gráficos rápidamente con Geogebra.\n\n\n\n\n\n\nPaso 1: postular \\(g(x)\\)\n\nReescribimos \\(f(x) = 0\\) como \\(x = g(x)\\)\nPor ejemplo, despejando la \\(x\\) del segundo término:\n\\[f(x) = x^2-3x+e^x-2 = 0\\] \\[\\implies x =  \\underbrace{\\frac{x^2+e^x-2}{3}}_{g(x)}\\] \\[\\implies g(x)= \\frac{x^2+e^x-2}{3}\\]\n\nPaso 2: verificar si \\(g(x)\\) cumple las condiciones del teorema\n\nVamos a concentrarnos en la raíz negativa, para ver si las condiciones del teorema se verifican en una vecindad de la misma.\nNecesitamos calcular la derivada de \\(g\\):\n\\[g'(x) = \\frac{1}{3}(2x+e^x)\\]\nLa forma más fácil de hacer la verificación es usando una gráfica. Hay que tomar un intervalo \\([a, b]\\) que contenga a la raíz y graficar \\(g\\) y \\(g'\\) para poder observar el cumplimiento o no de las condiciones.\nTomemos arbitrariamente el intervalo \\([-1.5, 0.5]\\). En la siguiente figura podemos ver que \\(g\\) es continua allí y que \\(g(x) \\in [a, b]\\) para todo \\(x \\in [a, b]\\) (la curva “sale por los costados” del cuadrado delimitado por el intervalo de interés).\n\n\n\n\n\nLa siguiente figura muestra la derivada, confirmando que está acotada por 1 en valor absoluto:\n\\[\ng'(x) = \\frac{1}{3} (2x+e^x)\n\\]\n\n\n\n\n\nLo anterior implica que hay una raíz dentro del intervalo \\([-1.5, 0.5]\\) y que empezando la sucesión con cualquier valor dentro del mismo vamos a llegar a la misma.\nOtra forma es demostrar analíticamente, por ejemplo, que la derivada está acotada por el valor \\(1\\) en valor absoluto en intervalo analizado. Como esto puede ser “complejo”, en la práctica a veces miramos sencillamente que tanto \\(|g'(a)|\\) como \\(|g'(b)|\\) sean menores que \\(1\\) (pero hay que tener cuidado, que se cumpla en los extremos de los intervalos no quiere decir que se cumpla en todo el intervalo).\nSi no se cumplen las condiciones, podemos probar igualmente si el método converge (aunque no hay garantías de eso) o probar con otra expresión para \\(g(x)\\) que sí cumpla con las condiciones.\n\nPaso 3: elegir un punto inicial y realizar las iteraciones\n\nImaginemos que en búsqueda de la raíz negativa estamos considerando el intervalo \\([-1.5, 0.5]\\) que como sabemos verifica las condiciones del teorema.\nDebemos tomar cualquier punto \\(p_0\\) dentro de este intervalo para iniciar el proceso iterativo.\nLa fórmula de recurrencia es:\n\\[\np_n= g(p_{n-1})=\\frac{p_{n-1}^2+e^{p_{n-1}}-2}{3}, \\qquad n = 1, 2, ...\n\\]\nque en este caso imlica:\n\\[\np_n= \\frac{p_{n-1}^2+e^{p_{n-1}}-2}{3}, \\qquad n = 1, 2, ...\n\\]\nTomando \\(p_0 = -1.5\\), el proceso converge al valor \\(-0.390271\\) que consideraremos como la aproximación para la raíz buscada.\n\n\n\n\n\nVerificar estos resultados (pueden hacerlo rápidamente en una planilla de Excel).\nPara saber cuándo detenernos, podemos fijar una toleracia \\(\\epsilon = 1E-6\\) (por ejemplo) y parar el proceso cuando la diferencia relativa entre dos aproximaciones sucesivas sea menor:\n\n\\[\n\\frac{|p_N - p_{N-1}|}{|p_N|} &lt; \\epsilon = 1E-6\n\\]\n::: {.cell layout-align=“center”} ::: {.cell-output-display}  ::: :::\nPaso 4: representar gráficamente\n\nComo hemos mencionado, el punto fijo de \\(g\\) se encuentra en el lugar donde la recta identidad interseca a \\(g\\).\nUna gráfica de ambas nos permite visualizar el proceso iterativo de forma gráfica (la curva azul es \\(g(x)\\) y la roja es la recta identidad):\n\n\n\n\n\n\n\n\n1.3.4 Casos convergentes y divergentes\n\nLas siguientes figuras presentan algunos ejemplos de convergencia y divergencia del proceso:",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Resolución de ecuaciones en una variable</span>"
    ]
  },
  {
    "objectID": "02_ecuaciones.html#el-método-de-newton-raphson",
    "href": "02_ecuaciones.html#el-método-de-newton-raphson",
    "title": "1  Resolución de ecuaciones en una variable",
    "section": "1.4 El método de Newton-Raphson",
    "text": "1.4 El método de Newton-Raphson\n\nEl método de Newton (o de Newton-Raphson) es uno de los métodos numéricos más poderosos y reconocidos para resolver un problema de encontrar la raíz.\nEste método propone tomar una aproximación inicial \\(p_0\\) para la raíz de la ecuación \\(f(x) = 0\\) y generar la sucesión \\(\\{p_n\\}_{n=0}^\\infty\\) mediante:\n\\[\np_n = p_{n-1} - \\frac{f(p_{n-1})}{f'(p_{n-1})} \\qquad n \\geq 1\n\\]\nSi se cumplen ciertas condiciones generales que estudiaremos más adelante, esta sucesión converge al verdadero valor buscado, la raíz \\(p\\).\nPara detener las iteraciones se emplea alguno de los criterios de parada mencionados cuando vimos el método de la bisección.\nAntes de ver cuáles son esas condiciones, vamos a ver de dónde surge esta fórmula de recurrencia y cómo la podemos interpretar geométricamente.\n\n\n1.4.1 Deducción de la fórmula de recurrencia\n\nSupongamos que \\(f\\) es continua en un intervalo \\([a, b]\\) y tiene derivadas primera y segunda continuas en el mismo intervalo.\nTomemos \\(p_0 \\in [a,b]\\) como un valor que se aproxima para \\(p\\) y consideremos el polinomio de Taylor de grado 1 para aproximar \\(f(x)\\) alrededor de \\(p_0\\):\n\\[f(x) = f(p_0) + (x-p_0) f'(p_0)+ \\underbrace{\\frac{(x-p_0)^2}{2!}f''(\\xi)}_{\\text{resto, } \\xi \\text{ real entre } x \\text{ y }p_0}\\]\nAhora, evaluemos el polinomio de Taylor en el valor verdadero \\(p\\):\n\\[\\text{Por ser $p$ la raíz de $f$:} \\quad f(p) = 0\\]\n\\[\\text{Por el desarrollo de Taylor:} \\quad f(p) = f(p_0) + (p-p_0) f'(p_0)+ \\underbrace{\\frac{(p-p_0)^2}{2!}f''(\\xi)}_{\\text{resto, } \\xi \\text{ real entre } p \\text{ y }p_0}\\]\n\\[\\text{Entonces:}\\quad 0 = f(p_0) + (p-p_0) f'(p_0)+\\frac{(p-p_0)^2}{2!}f''(\\xi)\\]\nSi \\(p_0\\) es una aproximación adecuada, \\(|p-p_0|\\) debe ser pequeño y entonces el término relacionado a \\((p-p_0)^2\\), mucho más pequeño y puede ser descartado, de modo que:\n\\[0 \\approx f(p_0) + (p-p_0) f'(p_0)\\]\nAl despejar \\(p\\) tenemos:\n\\[\np \\approx p_{0} - \\frac{f(p_{0})}{f'(p_{0})} \\equiv p_1\n\\]\nLlamamos al valor anterior \\(p_1\\) y repetimos el procedimiento planteando el desarrollo en serie de Taylor de \\(f\\) alrededor de \\(p_1\\), encontrando que:\n\\[\np \\approx p_{1} - \\frac{f(p_{1})}{f'(p_{1})} \\equiv p_2\n\\]\nSi seguimos repitiendo esto, damos lugar a una sucesión que debe acercarnos cada vez más al verdadero valor de \\(p\\):\n\\[\np_n = p_{n-1} - \\frac{f(p_{n-1})}{f'(p_{n-1})} \\qquad n \\geq 1\n\\]\n\n\n\n1.4.2 Interpretación geométrica\n\nRecordemos la definición de recta tangente:\n\n\nDefinición: una recta se dice que es tangente a una función \\(f\\) en un punto \\(a\\) cuando pasa por ese punto y su pendiente es \\(f'(a)\\). La ecuación de la recta tangente a la gráfica de la función en el punto \\((a, f(a))\\) es:\n\\[\ny = f(a) + f'(a) (x - a)\n\\]\n\n\n\n\n\n\n\nLa fórmula de recurrencia presentada anteriormente equivale a encontrar el próximo valor \\(p_n\\) como el punto en el que el eje de las abscisas interseca a la recta tangente a la gráfica de \\(f\\) en \\((p_{n-1}, f(p_{n-1}))\\).\nEs decir, al empezar con la aproximación inicial \\(p_0\\), la aproximación \\(p_1\\) es la intersección con el eje \\(x\\) de la recta tangente a la gráfica de \\(f\\) en \\((p_0, f(p_0)\\).\nLa aproximación \\(p_2\\) es la intersección con el eje \\(x\\) de la recta tangente a la gráfica de \\(f\\) en \\((p_1, f(p_1)\\) y así sucesivamente:\n\n\n\n\n\n\n\n¿De dónde sale que la fórmula de recurrencia equivale a esto de avanzar en la sucesión de acuerdo a las rectas tangentes? Hay que prestarle atención a las pendientes.\nPor ejemplo, por definición de recta tangente, sabemos que la pendiente de la tangente a \\(f\\) en \\(p_0\\) es igual a:\n\\[\nm = f'(p_0)\n\\]\nPero también sabemos que la pendiente se puede definir como el siguiente cociente, donde \\((x_0, y_0)\\) y \\((x_1, y_1)\\) son dos puntos cualesquiera pertenecientes a la recta:\n\\[\nm = \\frac{y_1 - y_0}{x_1 - x_0}\n\\]\nPodemos tomar los puntos \\((p_0, f(p_0))\\) y \\((p_1, 0)\\) (el punto donde la tangente interseca al eje \\(x\\)) y encontrar una expresión para la pendiente de la tangente:\n\\[\nm = \\frac{y_1 - y_0}{x_1 - x_0} =  \\frac{0 - f(p_0)}{p_1 - p_0}=  -\\frac{f(p_0)}{p_1 - p_0}\n\\]\nIgualando las dos expresiones equivalentes vistas para la pendiente \\(m\\):\n\\[\nf'(p_0) =  -\\frac{f(p_0)}{p_1 - p_0} \\implies\np_1 = p_{0} - \\frac{f(p_{0})}{f'(p_{0})}\n\\]\nSi repetimos este pensamiento con la recta tangente a \\(f\\) en el punto \\(p_1\\), vamos a encontrar que:\n\\[\n  p_2 = p_1 - \\frac{f(p_1)}{f'(p_1)}\n  \\]\nEsto constituye una derivación geométrica del método de Newton-Raphson desde el punto de vista de las rectas tangentes a \\(f\\) en los puntos \\(p_{n}\\).\n\n\n\n1.4.3 Convergencia\n\nLa derivación del método de Newton por medio de la serie de Taylor señala la importancia de una aproximación inicial precisa.\nLa suposición crucial es que el término relacionado con \\((p - p_0)^2\\) es, en comparación con \\(|p - p_0|\\), tan pequeño que se puede eliminar.\nClaramente esto será falso a menos que \\(p_0\\) sea una buena aproximación para \\(p\\). Si no lo es, no existen razones para sospechar que el método convergerá en la raíz (aunque en algunos casos incluso malas aproximaciones iniciales producen convergencia).\nEl siguiente teorema establece cuáles son las condiciones para el método converja, que básicamente se resumen en el hecho de que \\(p_0\\) tiene que estar suficientemente cerca de \\(p\\).\n\n\nTeorema: convergencia del método de Newton-Raphson:\nSea \\(f\\) continua en un intervalo \\([a, b]\\) con derivadas primera y segunda continuas en el mismo intervalo. Si \\(p \\in (a,b)\\) es tal que \\(f(p)=0\\) y \\(f'(p) \\neq 0\\), entonces existe \\(\\delta &gt;0\\) tal que el método de Newton-Raphson genera una sucesión \\(\\{p_n\\}_{n=0}^\\infty\\) que converge a \\(p\\) para cualquier aproximación inicial \\(p_0 \\in [p-\\delta,p+\\delta]\\).\n\n\nEl teorema se demuestra considerando que la sucesión propuesta por el método es una iteración de punto fijo. Repetimos la fórmula de recurrencia:\n\\[\np_n = \\underbrace{p_{n-1} - \\frac{f(p_{n-1})}{f'(p_{n-1})}}_{g(p_{n-1})}  \\qquad n \\geq 1\n\\]\nVemos que se trata de una iteración de punto fijo \\(p_n = g(p_{n-1})\\), en la que la función \\(g\\) es:\n\\[\ng(x) = x - \\frac{f(x)}{f'(x)}\n\\]\nPor lo tanto, el método converge cuando se cumplen las condiciones del Teorema del punto fijo:\n\n\\(g\\) es continua en \\([a, b]\\) y \\(g(x) \\in [a, b]\\) para todo \\(x \\in [a, b]\\).\n\\(g'(x)\\) existe en \\((a, b)\\) y existe una constante \\(0&lt;k&lt;1\\) con tal que \\(|g'(x)| \\leq k &lt; 1\\).\n\nAnalicemos solamente la condición acerca de que la derivada de \\(g\\) tiene que estar acotada:\n\\[|g'(x)| \\leq k &lt; 1\\]\nTomamos la derivada:\n\n\\[g'(x) = 1 - \\frac{[f'(x)]^2 - f(x)f''(x)}{[f'(x)]^2} = 1 - 1 + \\frac{f(x)f''(x)}{[f'(x)]^2} = \\frac{f(x)f''(x)}{[f'(x)]^2}\\]\n\nEs decir, el método convergerá si:\n\\[|g'(x)| = \\frac{|f(x)f''(x)|}{[f'(x)]^2} \\leq k &lt; 1\\]\nPor hipótesis, sabemos que \\(f(p) = 0\\); luego \\(g'(p) = 0\\). Como \\(g'(x)\\) es continua y \\(g'(p) = 0\\), siempre podemos encontrar un \\(\\delta &gt; 0\\) tal que \\(|g'(x)| &lt; 1\\) se cumpla en el intervalo \\([p - \\delta, p + \\delta]\\).\nPor consiguiente, que \\(p_0\\) se encuentre dentro de \\([p - \\delta, p + \\delta]\\) es una condición suficiente para que la sucesión \\(\\{x_n\\}_{n=0}^{\\infty}\\) converja a la única raíz de \\(f(x) = 0\\) en dicho intervalo.\nLa condición anterior tiene las siguientes implicancias. Para facilitar la convergencia:\n\n\\(p_0\\) tiene que estar suficientemente cerca de \\(p\\).\n\\(f''(x)\\) no debe ser muy grande y \\(f'(x)\\) no debe ser muy chica en ese intervalo.\n\nSi bien el teorema sirve para asegurar la convergencia, no dice cómo determinar \\(\\delta\\), así que en la práctica se selecciona una aproximación inicial y se generan aproximaciones sucesivas con el método de Newton. Puede que éstos converjan rápidamente a la raíz o será claro que la convergencia es poco probable.\nObservación: el método no puede continuar si \\(f'(p_{n-1}) = 0\\) para alguna \\(n\\).\n\n\n\n1.4.4 Ejemplo\n\nRetomemos el ejemplo anterior en cual buscábamos las raíces de la ecuación no lineal: \\(f(x) = x^2-3x+e^x-2=0\\)\nMediante el método del punto fijo reformulamos la ecuación anterior como \\(x = g(x)\\) con:\n\\[g(x)= \\frac{x^2+e^x-2}{3}\\]\nDe esa forma pudimos hallar la raíz negativa.\nSin embargo, el método no sirve para hallar la raíz positiva (verificar que no se cumplen las condiciones del teorema en vecindades de la raíz).\nSi bien podríamos probar con otra expresión para \\(g(x)\\), ¿podrá el método de Newton-Raphson sernos útil en este caso?\nVerificar.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Resolución de ecuaciones en una variable</span>"
    ]
  },
  {
    "objectID": "02_ecuaciones.html#variantes-del-método-de-newton-raphson",
    "href": "02_ecuaciones.html#variantes-del-método-de-newton-raphson",
    "title": "1  Resolución de ecuaciones en una variable",
    "section": "1.5 Variantes del método de Newton-Raphson",
    "text": "1.5 Variantes del método de Newton-Raphson\n\n1.5.1 Método de la secante\n\nEl método de Newton es una técnica en extremo poderosa, pero tiene una debilidad importante: la necesidad de conocer el valor de la derivada de \\(f\\) en cada aproximación.\n\\(f'(x)\\) puede ser más difícil y necesitar más operaciones aritméticas para ser calculada que \\(f(x)\\).\nPara evitar el problema de la evaluación de la derivada, el método de la secante presenta una ligera variación.\nPor definición de derivada:\n\\[\n  f'(p_{n-1}) = \\lim_{x \\rightarrow p_{n-1}} \\frac{f(x) - f(p_{n-1})}{x- p_{n-1}}\n  \\]\nSi \\(p_{n-2}\\) está cerca de \\(p_{n-1}\\):\n\\[\n  f'(p_{n-1}) \\approx  \\frac{f(p_{n-2}) - f(p_{n-1})}{p_{n-2}- p_{n-1}} = \\frac{f(p_{n-1}) - f(p_{n-2})}{p_{n-1}- p_{n-2}}\n  \\]\nUsando esta aproximación en la fórmula de Newton obtenemos:\n\\[\np_n = p_{n-1} - \\frac{f(p_{n-1})(p_{n-1}- p_{n-2})}{f(p_{n-1}) - f(p_{n-2})} \\qquad n \\geq 2\n\\]\nNotar que se necesitan dos aproximaciones iniciales.\nEste método también goza de una interpretación geométrica que es la que le da su nombre.\n\n\nDefinición: una recta secante es una recta que corta a una curva \\(f\\) en dos o más puntos. Conforme estos puntos se acercan y su distancia se reduce a cero, la recta secante pasa a ser la recta tangente.\nLa ecuación de la recta secante a \\(f\\) que pasa por los puntos \\((x_1, f(x_1))\\) y \\((x_2, f(x_2))\\) es (fórmula de la recta que pasa por dos puntos):\n\\[\ny = f(x_1) + \\frac{f(x_2) - f(x_1)}{x_2 - x_1} (x - x_1)\n\\]\n\n\n\n\n\n\n\nEmpezando con dos aproximaciones iniciales \\(p_0\\) y \\(p_1\\), la aproximación \\(p_2\\) es la intersección en \\(x\\) de la recta que une los puntos \\((p_0, f(p_0))\\) y \\((p_1, f(p_1))\\).\nLa aproximación \\(p_3\\) es la intersección en \\(x\\) de la recta que une los puntos \\((p_1, f(p_1))\\) y \\((p_2, f(p_2))\\) y así sucesivamente.\n::: {.cell layout-align=“center”} ::: {.cell-output-display}  ::: :::\nObservación: sólo se necesita una evaluación de la función por cada paso para el método de la secante después de haber determinado \\(p_2\\). En contraste, cada paso del método de Newton requiere una evaluación tanto de la función como de su derivada.\n\n\n\n1.5.2 Método de von Mises\n\nEn el método de Newton-Raphson, el denominador \\(f'(p_{n-1})\\) hace que geométricamente se pase de una aproximación a la siguiente por la tangente de la curva \\(y = f(x)\\) en el punto correspondiente a la aproximación presente \\(p_{n-1}\\).\nEsto puede producir problemas cuando se esté en puntos alejados de raíces y cerca de puntos donde el valor de \\(f'(x)\\) sea cercano a 0 (tangentes cercanas a la horizontal).\nPara resolver este problema, von Mises sugirió sustituir \\(f'(p_{n-1})\\) en el denominador por \\(f'(p_{0})\\).\nEs decir, obtener las aproximaciones de la sucesión por medio de rectas que son todas paralelas a la primera tangente.\nLa fórmula de recurrencia resultante es:\n\\[\np_n = p_{n-1} - \\frac{f(p_{n-1})}{f'(p_{0})} \\qquad n \\geq 1\n\\]\n\n\n\n\n\n\n\nSi la derivada requiere muchos cálculos, este método posee la ventaja de que la misma sólo debe ser evaluada una vez.\n\n\n\n1.5.3 Método de Newton-Raphson de 2º Orden\n\nOtra modificación al método de Newton-Raphson se deriva a partir de la utilización de un término más en el desarrollo por serie de Taylor de la función \\(f(x)\\).\nDada la existencia de las correspondientes derivadas, la fórmula de recurrencia resultante es:\n\\[\n  p_n = p_{n-1} + \\frac{f(p_{n-1})f'(p_{n-1})}{0.5 f(p_{n-1}) f''(p_{n-1}) - [f'(p_{n-1})]^2} \\qquad n \\geq 1\n  \\]\nEl método de Newton-Raphson de 2º orden llega más rápidamente a la raíz que el de primer orden, pero requiere de más cálculos y la desventaja de especificar también la derivada segunda.\nEjercicio propuesto: derivar la ecuación de recurrencia de este método de forma análoga a la derivación de la fórmula para el método de Newton-Raphson.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Resolución de ecuaciones en una variable</span>"
    ]
  }
]