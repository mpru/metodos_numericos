<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.467">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Métodos Numéricos con Python - 4&nbsp; Resolución de sistemas de ecuaciones no lineales y optimización</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./05_autovalores.html" rel="next">
<link href="./03_sistemas_lineales.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://hypothes.is/embed.js"></script>
<script>
  window.document.addEventListener("DOMContentLoaded", function (_event) {
    document.body.classList.add('hypothesis-enabled');
  });
</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./04_sistemasnolineales.html"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Resolución de sistemas de ecuaciones no lineales y optimización</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Métodos Numéricos con Python</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/mpru/metodos_numericos/" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <a href="./Métodos-Numéricos-con-Python.pdf" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
    <div class="dropdown">
      <a href="" title="Share" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Share"><i class="bi bi-share"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://twitter.com/intent/tweet?url=|url|">
              <i class="bi bi-bi-twitter pe-1"></i>
            Twitter
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.facebook.com/sharer/sharer.php?u=|url|">
              <i class="bi bi-bi-facebook pe-1"></i>
            Facebook
            </a>
          </li>
      </ul>
    </div>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Prefacio</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Conceptos básicos de análisis numérico</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02_ecuaciones.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Resolución de ecuaciones en una variable</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03_sistemas_lineales.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Resolución de sistemas de ecuaciones lineales</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04_sistemasnolineales.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Resolución de sistemas de ecuaciones no lineales y optimización</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05_autovalores.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Valores y vectores propios</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06_aprox_polin_parte1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Aproximación polinomial - Parte 1: interpolación</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06_aprox_polin_parte2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Aproximación polinomial - Parte 2: Derivación e integración</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Tabla de contenidos</h2>
   
  <ul>
  <li><a href="#introducción" id="toc-introducción" class="nav-link active" data-scroll-target="#introducción"><span class="header-section-number">4.1</span> Introducción</a></li>
  <li><a href="#sistemas-de-ecuaciones-no-lineales" id="toc-sistemas-de-ecuaciones-no-lineales" class="nav-link" data-scroll-target="#sistemas-de-ecuaciones-no-lineales"><span class="header-section-number">4.2</span> Sistemas de ecuaciones no lineales</a>
  <ul class="collapse">
  <li><a href="#método-de-los-puntos-fijos" id="toc-método-de-los-puntos-fijos" class="nav-link" data-scroll-target="#método-de-los-puntos-fijos"><span class="header-section-number">4.2.1</span> Método de los puntos fijos</a></li>
  <li><a href="#método-de-newton-o-de-newton-raphson-para-sistemas-de-ecuaciones" id="toc-método-de-newton-o-de-newton-raphson-para-sistemas-de-ecuaciones" class="nav-link" data-scroll-target="#método-de-newton-o-de-newton-raphson-para-sistemas-de-ecuaciones"><span class="header-section-number">4.2.2</span> Método de Newton (o de Newton-Raphson) para sistemas de ecuaciones</a></li>
  </ul></li>
  <li><a href="#optimización" id="toc-optimización" class="nav-link" data-scroll-target="#optimización"><span class="header-section-number">4.3</span> Optimización</a>
  <ul class="collapse">
  <li><a href="#método-de-newton-para-problemas-de-optimización" id="toc-método-de-newton-para-problemas-de-optimización" class="nav-link" data-scroll-target="#método-de-newton-para-problemas-de-optimización"><span class="header-section-number">4.3.1</span> Método de Newton para problemas de optimización</a></li>
  <li><a href="#técnicas-del-gradiente-descendiente" id="toc-técnicas-del-gradiente-descendiente" class="nav-link" data-scroll-target="#técnicas-del-gradiente-descendiente"><span class="header-section-number">4.3.2</span> Técnicas del gradiente descendiente</a></li>
  <li><a href="#fisher-scoring" id="toc-fisher-scoring" class="nav-link" data-scroll-target="#fisher-scoring"><span class="header-section-number">4.3.3</span> Fisher Scoring</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/mpru/metodos_numericos/edit/main/04_sistemasnolineales.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/mpru/metodos_numericos/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li><li><a href="https://github.com/mpru/metodos_numericos/blob/main/04_sistemasnolineales.qmd" class="toc-action"><i class="bi empty"></i>View source</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Resolución de sistemas de ecuaciones no lineales y optimización</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="introducción" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="introducción"><span class="header-section-number">4.1</span> Introducción</h2>
<!-- 

VIDEOS BUENOS
Why the gradient is the direction of steepest ascent
https://www.youtube.com/watch?v=TEB2z7ZlRAw

DERIVADA DIRECCIONAL
https://www.youtube.com/watch?v=N_ZRcLheNv0

GRADIENT DESCENT EN DEEP LEARNING
Gradient descent, how neural networks learn | Chapter 2, Deep learning
youtube.com/watch?v=IHZwWFHWa-w&t=276s
y toda la playlist sobre neural networks
https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi

-->
<ul>
<li><p>Un sistema de ecuaciones no lineales <span class="math inline">\(n \times n\)</span> tiene la forma:</p>
<p><span class="math display">\[
  \begin{cases}
  f_1(x_1, x_2, \cdots, x_n) = 0 \\
  f_2(x_1, x_2, \cdots, x_n) = 0 \\
  \vdots \\
  f_n(x_1, x_2, \cdots, x_n) = 0
  \end{cases}
  \]</span></p>
<p>donde cada función <span class="math inline">\(f_i\)</span> se puede pensar como un mapeo de un vector <span class="math inline">\(\mathbf{x} = (x_1, x_2, \cdots, x_n)^T\)</span> del espacio <span class="math inline">\(n\)</span>-dimensional <span class="math inline">\(\mathbb{R}^n\)</span> en la recta real <span class="math inline">\(\mathbb{R}\)</span>.</p></li>
<li><p>En la siguiente figura se muestra una representación geométrica de un sistema no lineal cuando <span class="math inline">\(n=2\)</span>.</p></li>
</ul>
<div class="cell">
<div class="cell-output-display">
<p><img src="Plots/U4/figura101.png" class="img-fluid" width="337"></p>
</div>
</div>
<ul>
<li><p>Este sistema de <span class="math inline">\(n\)</span> ecuaciones no lineales en <span class="math inline">\(n\)</span> variables también se puede representar al definir una función vectorial <span class="math inline">\(\mathbf{F}\)</span> de mapeo de <span class="math inline">\(\mathbb{R}^n\)</span> a <span class="math inline">\(\mathbb{R}^n\)</span> (es decir, un <em>campo vectorial</em>, así vamos nombrando cosas de Análisis y Álgebra):</p>
<p><span class="math display">\[
  \mathbf{F}(x_1, x_2, \cdots, x_n) =
  \begin{pmatrix}
  f_1(x_1, x_2, \cdots, x_n) \\
  f_2(x_1, x_2, \cdots, x_n) \\
  \vdots \\
  f_n(x_1, x_2, \cdots, x_n)
  \end{pmatrix}
  \]</span></p></li>
<li><p>Si se utiliza notación vectorial con <span class="math inline">\(\mathbf{x} = (x_1, x_2, \cdots, x_n)^T\)</span> y <span class="math inline">\(\mathbf{0} = (0, 0, \cdots, 0)^T\)</span>, entonces el sistema asume la forma:</p>
<p><span class="math display">\[
  \mathbf{F}(\mathbf{x}) = \mathbf{0}
  \]</span></p></li>
<li><p>Las funciones <span class="math inline">\(f_1, f_2, \cdots, f_n\)</span> reciben el nombre de <strong>funciones coordenadas</strong> de <span class="math inline">\(\mathbf{F}\)</span>.</p></li>
<li><p>Un acercamiento para la resolución de sistemas de ecuaciones no lineales es pensar si los métodos vistos en la Unidad 2 para resolver ecuaciones no lineales se pueden adaptar y generalizar.</p></li>
<li><p>Con eso en mente es posible generalizar, por ejemplo, el <strong>método del punto fijo</strong> y el <strong>método de Newton-Raphson</strong>, como veremos en la sección siguiente.</p></li>
<li><p>Hay algo muy interesante y es que la búsqueda de la solución de un sistema de ecuaciones no lineales puede ser formulado como un <strong>problema de optimización</strong>, es decir, un problema en el que se quiere hallar el máximo o el mínimo de función.</p></li>
<li><p>Por esta razón, en muchos libros se presenta de manera conjunta el estudio de métodos para resolver sistemas de ecuaciones no lineales y para resolver problemas de optimización, y ellos son el objeto de estudio de esta unidad.</p></li>
</ul>
<!-- como se puede consultar en la sección 10.1 del libro. -->
<!-- - A esta adaptación se la conoce como **Método de Newton** y es el método que se utilizar para poder estimar los parámetros en el ajuste de distintas clases de modelos.  -->
<!-- - Por esta razón, en asignaturas como **Modelos lineales generalizados** o **Análisis de Datos Categóricos** van a mencionar a este método (o pequeñas variantes del mismo). -->
</section>
<section id="sistemas-de-ecuaciones-no-lineales" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="sistemas-de-ecuaciones-no-lineales"><span class="header-section-number">4.2</span> Sistemas de ecuaciones no lineales</h2>
<section id="método-de-los-puntos-fijos" class="level3" data-number="4.2.1">
<h3 data-number="4.2.1" class="anchored" data-anchor-id="método-de-los-puntos-fijos"><span class="header-section-number">4.2.1</span> Método de los puntos fijos</h3>
<ul>
<li>En la Unidad 2 vimos un método para resolver una ecuación del tipo <span class="math inline">\(f(x)=0\)</span>, al transformar primero la ecuación en la forma de punto fijo <span class="math inline">\(x=g(x)\)</span>, tomar un valor inicial <span class="math inline">\(x_0\)</span> y luego iterar haciendo: <span class="math inline">\(x_k = g(x_{k-1})\)</span>.</li>
<li>Vamos a ver un proceso similar para las funciones de <span class="math inline">\(\mathbb{R}^n\)</span> a <span class="math inline">\(\mathbb{R}^n\)</span>.</li>
</ul>
<div class="alert alert-success">
<p><strong>Definición</strong>: una función <span class="math inline">\(\mathbf{G}\)</span> desde <span class="math inline">\(D \subset\mathbb{R}^n\)</span> a <span class="math inline">\(\mathbb{R}^n\)</span> tiene un punto fijo en <span class="math inline">\(\mathbf{p} \subset D\)</span> si <span class="math inline">\(\mathbf{G}(\mathbf p) = \mathbf p\)</span>.</p>
</div>
<ul>
<li><p>Para resolver el sistema de <span class="math inline">\(n\)</span> ecuaciones no lineales <span class="math inline">\(\mathbf{F}(\mathbf{x}) = \mathbf{0}\)</span>:</p>
<p><span class="math display">\[
  \begin{cases}
  f_1(x_1, x_2, \cdots, x_n) = 0 \\
  f_2(x_1, x_2, \cdots, x_n) = 0 \\
  \vdots \\
  f_n(x_1, x_2, \cdots, x_n) = 0
  \end{cases}
  \]</span></p>
<p>primero debemos reescribir cada ecuación bajo la forma:</p>
<p><span class="math display">\[
  \begin{cases}
  x_1 = g_1(x_1, x_2, \cdots, x_n)  \\
  x_2 = g_2(x_1, x_2, \cdots, x_n) \\
  \vdots \\
  x_n = g_n(x_1, x_2, \cdots, x_n)
  \end{cases}
  \]</span></p></li>
<li><p>Llamamos con <span class="math inline">\(\mathbf{G}\)</span> a la función de mapeo <span class="math inline">\(\mathbb{R}^n\)</span> en <span class="math inline">\(\mathbb{R}^n\)</span> que reune a todas las funciones <span class="math inline">\(g_i\)</span>:</p>
<p><span class="math display">\[
  \mathbf{G}(\mathbf x) =
  \begin{pmatrix}
  g_1(x_1, x_2, \cdots, x_n) \\
  g_2(x_1, x_2, \cdots, x_n) \\
  \vdots\\
  g_n(x_1, x_2, \cdots, x_n)
  \end{pmatrix}
  \]</span></p></li>
<li><p>Elegimos un vector de valores iniciales <span class="math inline">\(\mathbf x^{(0)} = (x_1^{(0)}, x_2^{(0)}, \cdots, x_n^{(0)})^T\)</span> y efectuamos el proceso iterativo</p></li>
</ul>
<p><span class="math display">\[
\mathbf x^{(k)} = \mathbf{G}(\mathbf x^{(k-1)}) \qquad k \geq 1
\]</span></p>
<ul>
<li><p>Si converge, encontraremos el punto fijo de <span class="math inline">\(\mathbf{G}\)</span> que no es más que la solución de <span class="math inline">\(\mathbf{F}(\mathbf{x}) = \mathbf{0}\)</span>.</p></li>
<li><p>El Teorema 10.6 del libro (página 479) establece cuáles son las condiciones para garantizar la existencia y unicidad del punto fijo, además de asegurar la convergencia del método. Estas condiciones son generalizaciones de las que vimos para el teorema del punto fijo en la Unidad 2.</p></li>
<li><p>Sin embargo, no siempre es posible o fácil encontrar una representación de las funciones en una forma que requiere el método y que además cumpla con las condiciones para la convergencia.</p></li>
<li><p>Otra opción es adaptar el método de Newton-Raphson, lo cual resulta en una de las técnicas más potentes y ampliamente usadas para resolver sistemas no lineales y de optimización.</p></li>
</ul>
</section>
<section id="método-de-newton-o-de-newton-raphson-para-sistemas-de-ecuaciones" class="level3" data-number="4.2.2">
<h3 data-number="4.2.2" class="anchored" data-anchor-id="método-de-newton-o-de-newton-raphson-para-sistemas-de-ecuaciones"><span class="header-section-number">4.2.2</span> Método de Newton (o de Newton-Raphson) para sistemas de ecuaciones</h3>
<section id="formalización" class="level4" data-number="4.2.2.1">
<h4 data-number="4.2.2.1" class="anchored" data-anchor-id="formalización"><span class="header-section-number">4.2.2.1</span> Formalización</h4>
<ul>
<li><p>Recordemos que para resolver una ecuación no lineal del tipo <span class="math inline">\(f(x) =0\)</span>, a partir del desarrollo de Taylor deducimos el siguiente proceso iterativo para resolverlo:</p>
<p><span class="math display">\[
x_k = x_{k-1} - \frac{f(x_{k-1})}{f'(x_{k-1})} = x_{k-1} - [f'(x_{k-1})]^{-1} f(x_{k-1}) \qquad k \geq 1
\]</span></p>
<p>el cual converge siempre que se tome un buen valor inicial <span class="math inline">\(x_0\)</span>.</p></li>
<li><p>Para resolver un sistema no lineal <span class="math inline">\(n \times n\)</span>, se extiende esta idea al proponer el siguiente procedimiento de iteración:</p></li>
</ul>
<p><span class="math display">\[
\mathbf{x}^{(k)}= \mathbf{x}^{(k-1)} - [\mathbf{J}(\mathbf{x}^{(k-1)})]^{-1} \mathbf{F}(\mathbf{x}^{(k-1)}) \qquad k \geq 1
\]</span></p>
<ul>
<li>La matriz <span class="math inline">\(\mathbf{J}(\mathbf{p})\)</span> se llama <strong>matriz jacobiana</strong>. El elemento en la posición <span class="math inline">\((i, j)\)</span> es la derivada parcial de <span class="math inline">\(f_i\)</span> con respecto a <span class="math inline">\(x_j\)</span>:</li>
</ul>
<p><span class="math display">\[
\mathbf{J} (\mathbf{x}) =
\begin{bmatrix}
  \frac{\partial f_1}{\partial x_1} (\mathbf{x}) &amp;
    \frac{\partial f_1}{\partial x_2}(\mathbf{x}) &amp; \cdots &amp;
    \frac{\partial f_1}{\partial x_n}(\mathbf{x}) \\[1ex]
  \frac{\partial f_2}{\partial x_1}(\mathbf{x}) &amp;
    \frac{\partial f_2}{\partial x_2}(\mathbf{x}) &amp; \cdots &amp;
    \frac{\partial f_2}{\partial x_n}(\mathbf{x}) \\[1ex]
   \vdots &amp; \vdots &amp;\ddots &amp; \vdots \\[1ex]
  \frac{\partial f_n}{\partial x_1}(\mathbf{x}) &amp;
    \frac{\partial f_n}{\partial x_2}(\mathbf{x}) &amp;  \cdots &amp;
    \frac{\partial f_n}{\partial x_n}(\mathbf{x})
\end{bmatrix}
\]</span></p>
<ul>
<li>Esto recibe el nombre de <strong>Método de Newton para sistemas no lineales</strong>.</li>
<li>Se demuestra que converge a la verdadera solución <span class="math inline">\(\mathbf{p}\)</span> siempre que se tome un buen vector inicial <span class="math inline">\(\mathbf{x}^{(0)}\)</span> (lo mismo que pasaba con el método de Newton-Raphson) y que exista <span class="math inline">\([\mathbf{J}(\mathbf{p})]^{-1}\)</span>.</li>
<li>Su convergencia es <em>cuadrática</em>, lo cual significa que es rápido.</li>
</ul>
</section>
<section id="métodos-cuasi-newton" class="level4" data-number="4.2.2.2">
<h4 data-number="4.2.2.2" class="anchored" data-anchor-id="métodos-cuasi-newton"><span class="header-section-number">4.2.2.2</span> Métodos cuasi-Newton</h4>
<ul>
<li>La gran desventaja del método de Newton es tener que calcular e invertir la matriz <span class="math inline">\(\mathbf{J}(\mathbf{x})\)</span> en cada paso, lo cual implica realizar muchos cálculos, además de que la evaluación exacta de las derivadas parciales <span class="math inline">\(\frac{\partial f_i}{\partial x_j}(\mathbf{x})\)</span> puede no ser práctica o sencilla.</li>
<li>Existen numerosas propuestas que persiguen el objetivo de reemplazar de alguna forma la matriz jacobiana con una matriz de aproximación que pueda ser actualizada fácilmente en cada iteración.</li>
<li>El conjunto de estos algoritmos se conocen como <strong>métodos cuasi-Newton</strong>.</li>
<li>Los <strong>métodos cuasi-Newton</strong> tienen una convergencia más lenta, pero resultan aceptables porque reducen la cantidad de cálculos a realizar.</li>
<li>Por ejemplo, habíamos visto que el <strong>método de la secante</strong> era una opción para reemplazar el cálculo de la derivada en el método de Newton-Raphson para resolver una ecuación no lineal. Esa idea se puede extender para sistemas de ecuaciones no lineales, resultando en un método conocido como <strong>método de Broyden</strong> (desarrollado en la sección 10.3 del libro, no lo estudiaremos, pero lo mencionamos por tener amplia difusión y aparecer en numerosas aplicaciones).</li>
</ul>
</section>
</section>
</section>
<section id="optimización" class="level2" data-number="4.3">
<h2 data-number="4.3" class="anchored" data-anchor-id="optimización"><span class="header-section-number">4.3</span> Optimización</h2>
<div class="alert alert-success">
<p><strong>Definición</strong>: la <strong>optimización matemática</strong> se encarga de resolver problemas en los que se debe encontrar el <em>mejor</em> elemento de acuerdo a algún criterio entre un conjunto de alternativas disponibles.</p>
</div>
<ul>
<li><p>Los problemas de optimización aparecen todo el tiempo en disciplinas como ciencias de la computación, ingeniería y, en lo que nos interesa a nosotros, Estadística.</p></li>
<li><p>Uno de los problemas de optimización más generales es el de encontrar el valor de <span class="math inline">\(\mathbf{x}\)</span> que minimice o maximice una función dada <span class="math inline">\(f(\mathbf{x})\)</span>, sin estar sujeto a ninguna restricción sobre <span class="math inline">\(\mathbf{x}\)</span>.</p></li>
<li><p>En Análisis Matemático ya han resuelto problemas de optimización, aunque tal vez los hayan presentados como <strong>problemas de máximos y mínimos</strong>.</p></li>
<li><p>La <strong>optimización matemática</strong> es también llamada <strong>programación matemática</strong>, pero acá el término <em>programación</em> no hace referencia a programar una computadora, sino que históricamente se le decía así a este tipo de problemas. En la actualidad, se sigue usando esa palabra para darle nombre al campo de la <strong>programación lineal</strong>, que engloba a los problemas de optimización donde la función a optimizar y las restricciones que se deben verificar están representadas por relaciones lineales.</p></li>
<li><p>La resolución de sistemas de ecuaciones (lineales o no) tiene una estrecha relación con los problemas de optimización.</p></li>
<li><p>Esto es así porque el problema de encontrar la solución de un sistema de ecuaciones puede ser reformulado como un problema en el que se necesita encontrar el mínimo de una función multivariada en particular.</p></li>
<li><p>El sistema definido por:</p>
<p><span class="math display">\[
  \begin{cases}
  f_1(x_1, x_2, \cdots, x_n) = 0 \\
  f_2(x_1, x_2, \cdots, x_n) = 0 \\
  \vdots \\
  f_n(x_1, x_2, \cdots, x_n) = 0
  \end{cases}
  \]</span></p>
<p>tiene una solución en <span class="math inline">\(\mathbf{x} = (x_1, x_2, \cdots, x_n)^T\)</span> precisamente cuando la función <span class="math inline">\(g\)</span> definida por:</p>
<p><span class="math display">\[
  g(x_1, x_2, \cdots, x_n) = \sum_{i=1}^n [f_i(x_1, x_2, \cdots, x_n)]^2
  \]</span></p>
<p>tiene el valor mínimo 0.</p></li>
<li><p>Por esta razón ahora plantearemos de forma más general al método de Newton y sus derivados como métodos de optimización, ya que es así como suelen aparecer en la literatura y, en particular, cuando se recurre a ellos en estadística y <em>machine learning</em>.</p></li>
<li><p>En esas aplicaciones, la función que se desea minimizar es una <em>función de pérdida</em> o <em>de costo</em> y las incógnitas son los valores de los parámetros que producen el valor mínimo. Es decir, <span class="math inline">\(g\)</span> puede ser, por ejemplo, la <em>función mínimo cuadrática</em> (en un modelo de regresión que se estima por mínimos cuadradados) o el opuesto de la log-verosimilitud (en un modelo que se estima por máxima verosimilitud) y en lugar de usar la notación de <span class="math inline">\(x_1, x_2, \cdots, x_n\)</span>, buscaríamos valores para los parámetros <span class="math inline">\(\beta_1, \beta_2, \cdots, \beta_p\)</span> o <span class="math inline">\(\theta_1, \theta_2, \cdots, \theta_p\)</span>.</p></li>
<li><p>Si el problema original se trata de resolver un sistema de ecuaciones lineales, ya vimos que lo podemos convertir sencillamente en un problema de optimización. Al crear la función <span class="math inline">\(g\)</span> sumando al cuadrado todas las ecuaciones del sistema, hallamos la solución del mismo cuando buscamos el vector que minimiza <span class="math inline">\(g\)</span>.</p></li>
</ul>
<section id="método-de-newton-para-problemas-de-optimización" class="level3" data-number="4.3.1">
<h3 data-number="4.3.1" class="anchored" data-anchor-id="método-de-newton-para-problemas-de-optimización"><span class="header-section-number">4.3.1</span> Método de Newton para problemas de optimización</h3>
<ul>
<li><p>Recordemos el método de Newton para sistemas de ecuaciones no lineales:</p>
<p><span class="math display">\[
  \mathbf{x}^{(k)}= \mathbf{x}^{(k-1)} - [\mathbf{J}(\mathbf{x}^{(k-1)})]^{-1} \mathbf{F}(\mathbf{x}^{(k-1)}) \qquad k \geq 1
  \]</span></p></li>
<li><p>Queremos adaptarlo para resolver problemas de optimización.</p></li>
<li><p><strong>Objetivo</strong>: encontrar el vector <span class="math inline">\(\mathbf{x}\)</span> que minimiza la función <span class="math inline">\(g(\mathbf{x})\)</span>.</p></li>
<li><p>Sabemos que para encontrar un extremo debemos derivar la función con respecto a cada variable, igualar a cero y resolver el sistema de ecuaciones resultante:</p></li>
</ul>
<p><span class="math display">\[
\begin{cases}
\frac{\partial g}{\partial x_1}(\mathbf{x}) = 0\\
\frac{\partial g}{\partial x_2}(\mathbf{x}) = 0\\
\vdots\\
\frac{\partial g}{\partial x_n}(\mathbf{x}) = 0\\
\end{cases}
\]</span></p>
<ul>
<li>Haciendo uso de la definición de <em>gradiente</em>, podemos simplificar la escritura del sistema anterior:</li>
</ul>
<div class="alert alert-success">
<p><strong>Definición</strong>: Para <span class="math inline">\(g: \mathbb{R}^n \rightarrow\mathbb{R}\)</span> el gradiente de <span class="math inline">\(g\)</span> en <span class="math inline">\(\mathbf{x}=(x_1, \cdots, x_n)^T\)</span> se denota <span class="math inline">\(\nabla g(\mathbf{x})\)</span> y se define como:</p>
<p><span class="math display">\[
\nabla g(\mathbf{x}) = \Big(\frac{\partial g}{\partial x_1}(\mathbf{x}), \frac{\partial g}{\partial x_2}(\mathbf{x}), \cdots, \frac{\partial g}{\partial x_n}(\mathbf{x}) \Big)^T
\]</span></p>
</div>
<ul>
<li><p>El gradiente de una función multivariable es análogo a la derivada de una función de una sola variable. Recordemos que la derivada de una función mide la rapidez con la que cambia el valor de dicha función, según cambie el valor de su variable independiente.</p></li>
<li><p>El gradiente es una generalización de esta idea para funciones de más de una variable. De hecho, el término <em>gradiente</em> proviene de la palabra latina <em>gradi</em> que significa “caminar”. En este sentido, el gradiente de una superficie indica la dirección hacia la cual habría que caminar para ir “hacia arriba” lo más rápido posible. Por el contrario, el opuesto del gradiente <span class="math inline">\(\nabla g(\mathbf{x})\)</span> indica la dirección hacia la cual se puede “bajar” lo más rápido posible.</p></li>
<li><p>Podemos interpretar que un gradiente mide cuánto cambia el <em>output</em> de una función cuando sus <em>inputs</em> cambian un poquito.</p></li>
</ul>
<!-- en el sentido que una función multivariable diferenciable puede tener un mínimo relativo en $\mathbf{x}$ sólo cuando el gradiente de $\mathbf{x}$ es el vector cero. -->
<ul>
<li>Volviendo al sistema que tenemos que resolver, lo podemos escribir así:</li>
</ul>
<p><span class="math display">\[
\nabla g(\mathbf{x}) =\mathbf{0}
\]</span></p>
<ul>
<li>Y el método de Newton visto antes, ahora queda así:</li>
</ul>
<p><span class="math display">\[
\mathbf{x}^{(k)}= \mathbf{x}^{(k-1)} - [\mathbf{H}(\mathbf{x}^{(k-1)})]^{-1} \nabla g(\mathbf{x}^{(k-1)}) \qquad k \geq 1
\]</span></p>
<ul>
<li>Por un lado, el lugar del vector de funciones <span class="math inline">\(\mathbf{F}\)</span> es ocupado por el gradiente <span class="math inline">\(\nabla g\)</span>.</li>
<li>Por otro lado, también tuvimos que reemplazar la matriz jacobiana <span class="math inline">\(\mathbf{J}\)</span> que contenía las derivadas parciales de <span class="math inline">\(\mathbf{F}\)</span> por una matriz con las derivadas parciales del gradiente <span class="math inline">\(\nabla g\)</span>, es decir, por una matriz que contiene las derivadas parciales segundas de <span class="math inline">\(g\)</span>.</li>
<li>Esta matriz se simboliza con <span class="math inline">\(\mathbf{H}\)</span> y se llama <strong>matriz hessiana</strong>.</li>
</ul>
<div class="alert alert-success">
<p><strong>Definición</strong>: Para <span class="math inline">\(g: \mathbb{R}^n \rightarrow\mathbb{R}\)</span> cuyas segundas derivadas parciales existen y son continuas sobre el dominio de la función, la <strong>matriz hessiana</strong> de <span class="math inline">\(g\)</span> denotada por <span class="math inline">\(\mathbf{H}(\mathbf{x})\)</span> es una matriz cuadrada <span class="math inline">\(n\times n\)</span> con elementos:</p>
<p><span class="math display">\[
h_{ij} = \frac{\partial^2 g}{\partial x_i\partial x_j}
\]</span></p>
<p>es decir:</p>
<p><span class="math display">\[
\mathbf{H} (\mathbf{x}) =
\begin{bmatrix}
\frac{\partial^2 g}{\partial^2 x_1} (\mathbf{x}) &amp;
\frac{\partial^2 g}{\partial x_1 \partial x_2}(\mathbf{x}) &amp; \cdots &amp;
\frac{\partial^2 g}{\partial x_1\partial x_n}(\mathbf{x}) \\[1ex]
\frac{\partial^2 g}{\partial x_2\partial x_1}(\mathbf{x}) &amp;
\frac{\partial^2 g}{\partial^2 x_2}(\mathbf{x}) &amp; \cdots &amp;
\frac{\partial^2 g}{\partial x_2 \partial x_n}(\mathbf{x}) \\[1ex]
\vdots &amp; \vdots &amp;\ddots &amp; \vdots \\[1ex]
\frac{\partial^2 g}{\partial x_n\partial x_1}(\mathbf{x}) &amp;
\frac{\partial^2 g}{\partial x_n\partial x_2}(\mathbf{x}) &amp;  \cdots &amp;
\frac{\partial^2 g}{\partial^2 x_n}(\mathbf{x})
\end{bmatrix}
\]</span></p>
</div>
<ul>
<li>En otras palabras, la matriz hessiana es la matriz jacobiana del vector gradiente.</li>
<li>Si <span class="math inline">\(g\)</span> es una función convexa<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>, <span class="math inline">\(\mathbf{H}\)</span> es semidefinida positiva<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> y el método de Newton nos permite encontrar un mínimo (absoluto o local).</li>
<li>Si <span class="math inline">\(g\)</span> es una función cóncava, <span class="math inline">\(\mathbf{H}\)</span> es semidefinida positiva y el método de Newton nos permite encontrar un mínimo (absoluto o local).</li>
<li>No nos interesa ahora recordar estas cuestiones, pero sólo vamos a mencionar que en la mayoría de las aplicaciones de este método para el análisis de datos se trabaja con funciones convexas donde el objetivo es encontrar un mínimo.</li>
</ul>
</section>
<section id="técnicas-del-gradiente-descendiente" class="level3" data-number="4.3.2">
<h3 data-number="4.3.2" class="anchored" data-anchor-id="técnicas-del-gradiente-descendiente"><span class="header-section-number">4.3.2</span> Técnicas del gradiente descendiente</h3>
<ul>
<li><p>Miremos de nuevo la fórmula de Newton:</p>
<p><span class="math display">\[
  \mathbf{x}^{(k)}= \mathbf{x}^{(k-1)} - [\mathbf{H}(\mathbf{x}^{(k-1)})]^{-1} \nabla g(\mathbf{x}^{(k-1)})
  \]</span></p></li>
<li><p>Recordamos que la ventaja de este método es su velocidad de convergencia una vez que se conoce una aproximación inicial suficientemente exacta.</p></li>
<li><p>Pero sus desventajas incluyen la necesidad una aproximación inicial precisa para garantizar la convergencia y de tener que recalcular <span class="math inline">\([\mathbf{H}(\mathbf{x})]^{-1}\)</span> en cada paso.</p></li>
<li><p>¿Con qué se podría reemplazar <span class="math inline">\([\mathbf{H}(\mathbf{x})]^{-1}\)</span>?</p></li>
<li><p>Siendo que para actualizar <span class="math inline">\(\mathbf{x}\)</span> en cada paso se le resta <span class="math inline">\([\mathbf{H}(\mathbf{x})]^{-1} \nabla g(\mathbf{x})\)</span>, podemos pensar que los elementos de la matriz <span class="math inline">\([\mathbf{H}(\mathbf{x})]^{-1}\)</span> no son más que un conjunto de <em>coeficientes</em> o <em>pesos</em> que regulan “cuánto” hay que restarle a <span class="math inline">\(\mathbf{x}^{(k-1)}\)</span> para generar el siguiente vector <span class="math inline">\(\mathbf{x}^{(k)}\)</span>.</p></li>
<li><p>Entonces una propuesta es reemplazarlos por otro conjunto de pesos que sean más fáciles de obtener, aunque tal vez no lleguen a la convergencia tan rápido como los que fueron deducidos gracias al desarrollo en serie de Taylor.</p></li>
<li><p>¿Cuál sería la forma más fácil de obtener pesos para este proceso iterativo? Algunas ideas:</p>
<ol type="a">
<li>¡No usar nada! Es decir: <span class="math inline">\(\mathbf{x}^{(k)}= \mathbf{x}^{(k-1)} - \nabla g(\mathbf{x}^{(k-1)})\)</span></li>
<li>Elegirlos “a mano” y setearlos como si fuesen <em>hiper-parámetros</em> a configurar en el método.</li>
<li>En lugar de usar una matriz de pesos, usar sólo un número real.</li>
</ol></li>
<li><p>Vamos a ir por la última idea y vamos a llamar <span class="math inline">\(\alpha\)</span> a ese único escalar que utilizaremos como peso, lo que da lugar a una técnica se conoce como <strong>método del gradiente descendiente</strong> o <strong>descenso de gradiente</strong> (conocido en inglés como <em>gradient descent</em>).</p></li>
<li><p>Aunque persigue la misma idea, no es considerado un método cuasi-Newton, porque no usa derivadas segundas (no es de segundo orden).</p></li>
<li><p>Este método es ampliamente utilizado para poder ajustar modelos, desde casos sencillos como los modelos de regresión lineal, hasta otros más sofisticados que suelen englobarse bajo el campo del <em>machine learning</em> como las redes neuronales. En todos los casos, para ajustar el modelo es necesario minimizar alguna función de pérdida.</p></li>
<li><p>El proceso iterativo resulta ser igual a:</p></li>
</ul>
<p><span class="math display">\[
\mathbf{x}^{(k)}= \mathbf{x}^{(k-1)} - \alpha\nabla g(\mathbf{x}^{(k-1)}) \qquad k \geq 1
\]</span></p>
<ul>
<li>El opuesto del gradiente <span class="math inline">\(-\nabla g(\mathbf{x})\)</span> nos indica la dirección hacia la cual hay que ir para “bajar” lo más rápido posible por la superficie de <span class="math inline">\(g\)</span> cuando estamos parados en <span class="math inline">\(\mathbf{x}\)</span>, pero la constante <span class="math inline">\(\alpha\)</span> es la que determina cuánto vamos a “avanzar” en esa dirección. Por eso, recibe el nombre de <strong>tasa de aprendizaje</strong>.</li>
</ul>
<div class="cell" data-out.witdh="40%">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Plots/U4/gradiente.png" class="img-fluid figure-img" width="366"></p>
<figcaption>Representación del método del gradiente descendiente si <span class="math inline">\(g\)</span> fuese univarida. Notar que es una idea semejante a la que estudiamos con Newton-Rahpson para resolver ecuaciones no lineales.</figcaption>
</figure>
</div>
</div>
</div>
<ul>
<li>Si <span class="math inline">\(\alpha\)</span> es muy pequeña, este procedimiento tardará mucho en encontrar la solución adecuada, pero si es muy grande puede que no se llegue al mínimo porque el algoritmo podría ir y venir por las “laderas” de la superficie.</li>
</ul>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Plots/U4/alfa.png" class="img-fluid figure-img" style="width:50.0%"></p>
<figcaption>Tasa de aprendizaje grande (izquierda) y tasa de aprendizaje pequeña (derecha)</figcaption>
</figure>
</div>
</div>
</div>
<!-- A good way to make sure gradient descent runs properly is by plotting the cost function as the optimization runs. Put the number of iterations on the x-axis and the value of the cost-function on the y-axis. This helps you see the value of your cost function after each iteration of gradient descent, and provides a way to easily spot how appropriate your learning rate is. You can just try different values for it and plot them all together. The left image below shows such a plot, while the image on the right illustrates the difference between good and bad learning rates.  -->
<ul>
<li><p>El <strong>método del descenso más rápido</strong> (<em>steepest descent</em>) es un caso especial de gradiente descendiente en el cual la tasa de aprendizaje <span class="math inline">\(\alpha\)</span> se elige en cada paso de forma que se minimice el valor de la función objetivo <span class="math inline">\(g\)</span> en el próximo vector de la sucesión:</p>
<p><span class="math display">\[\alpha \quad / \quad g(\mathbf{x}^{(k-1)} - \alpha\nabla g(\mathbf{x}^{(k-1)})) \quad \text{sea mínimo}\]</span></p></li>
<li><p>Este método está presentado en la sección 10.4 del libro (pero no lo vamos a estudiar).</p></li>
</ul>
<p><strong>Analogía</strong></p>
<div class="cell">
<div class="cell-output-display">
<p><img src="Plots/U4/montaña.jpg" class="img-fluid" style="width:40.0%"></p>
</div>
</div>
<ul>
<li><p>En muchos textos se explica la idea general de la técnica del gradiente descendiente con la siguiente analogía.</p></li>
<li><p>Imaginemos que una persona está perdida en una montaña y está tratando de descender (es decir, está buscando el mínimo global de esa superficie). Hay mucha niebla y por lo tanto la visibilidad es muy baja. No se ve a lo lejos y la persona tiene que decidir hacia dónde ir mirando sólo a su alrededor, en su posición actual.</p></li>
<li><p>Lo que puede hacer es usar el método del gradiente descendiente: mirar la pendiente alrededor de dónde está y avanzar hacia la dirección con la mayor pendiente hacia abajo. Repitiendo este procedimiento a cada rato, eventualmente llegará a la base de la montaña (o a un valle intermedio…).</p></li>
<li><p>También podemos suponer que no es fácil determinar a simple vista hacia qué dirección desde donde está hay una pendiente más empinada y para definirlo necesita usar algún instrumento sofisticado que capte la inclinación del piso. Claramente, la persona no puede medir a cada rato porque si no va a perder mucho tiempo usando ese instrumento y avanzará de forma muy lenta. Tampoco puede “recalcular” su dirección poco frecuentemente porque podría caminar mucho en una dirección equivocada. Tiene que darse cuenta la frecuencia adecuada para hacer las mediciones si quiere descender antes de que anochezca.</p></li>
<li><p>En esta analogía, la persona es el algoritmo, la inclinación del terreno representa la pendiente de la superficie de la función a minimizar en el punto donde está parado, el instrumento para medir esa inclinación es la diferenciación, la dirección que elige para avanzar es la que determina el opuesto del gradiente y la frecuencia con la que hace las mediciones es la tasa de aprendizaje.</p></li>
</ul>
<p><strong>Mínimos locales</strong></p>
<!-- Esto resulta en un gran número de dimensiones si lo interpretamos geométricamente. Así que lo que antes era un mínimo local ahora se denomina punto de silla (saddle point en inglés).

Un punto de silla o punto de ensilladura es el punto sobre una superficie en el que la pendiente es cero pero no se trata de un extremo local (máximo o mínimo). Es el punto sobre una superficie en el que la elevación es máxima en una dirección y mínima en la dirección perpendicular. 

En los puntos de silla, el gradiente disminuye hasta cero en algunas dimensiones, pero sigue habiendo gradiente relevante en otras dimensiones. -->
<ul>
<li>Cuando usamos el gradiente descendiente nos arriesgamos a caer en un mínimo local.</li>
<li>Para evitarlo, se desarrollaron varias estrategias.</li>
<li>Una muy popular por su simplicidad es la de empezar el gradiente descendiente en distintos puntos al azar y elegir la mejor solución.</li>
<li>Sin embargo, se ha comprobado que, en la práctica, el riesgo de caer en un mínimo local es muy bajo, al menos en los problemas de ajuste de modelos con muchas variables.</li>
</ul>
<p><strong>Otras versiones</strong></p>
<ul>
<li>La versión del gradiente descendiente que hemos visto es la más básica.</li>
<li>Hay varias adaptaciones que se han ido realizando a lo largo de los años: gradiente descendiente estocástico, momentum, AdaGrad, RMSProp, Adam, batch, mini-batch, etc.</li>
<li>Algunas de estas mejoras hacen que el elegir el ratio de aprendizaje adecuado no sea tan relevante ya que lo van adaptando sobre la marcha.</li>
<li>En general, todas estas técnicas del gradiente descendiente resuelven un problema de minimización con una convergencia más lenta (lineal) que la de Newton pero con la ventaja de que normalmente también convergen con aproximaciones iniciales pobres y en ocasiones se lo usa para encontrar aproximaciones iniciales suficientemente exactas para las técnicas con base en Newton.</li>
</ul>
</section>
<section id="fisher-scoring" class="level3" data-number="4.3.3">
<h3 data-number="4.3.3" class="anchored" data-anchor-id="fisher-scoring"><span class="header-section-number">4.3.3</span> Fisher Scoring</h3>
<ul>
<li><p>En Estadística los problemas de optimización suelen aparecer en el ajuste de modelos. Por ejemplo, mediante el enfoque máximo verosímil, los estimadores de los parámetros de un modelo son aquellos valores que maximizan la log-verosimilitud de la muestra (<span class="math inline">\(log L\)</span>) y se emplea el método de Newton para obtenerlos.</p></li>
<li><p>Como dijimos antes, la desventaja del método de Newton es tener que calcular e invertir en cada paso una matriz que involucra derivadas, es decir, la matriz hessiana en la formulación que estamos discutiendo.</p></li>
<li><p>En el contexto de los Modelos Lineales Generalizados (<em>MLG</em>, una familia muy amplia de modelos que incluye a los modelos lineales que ya conocen y que tiene su propia asignatura en la carrera), la matriz hessiana resulta ser igual al opuesto de la <em>matriz de información observada</em> (es decir, <span class="math inline">\(\mathbf{H} = -\mathbf{I}\)</span>, pero no importa si no recordamos ahora estos conceptos de Inferencia).</p></li>
<li><p>Un pequeño cambio que simplifica los cálculos es reemplazarla por su esperanza, que es la <em>matriz de información de Fisher</em>, <span class="math inline">\(\mathcal{I}\)</span> (es decir se reemplaza <span class="math inline">\(\mathbf{H}^{-1}\)</span> por <span class="math inline">\(-\mathcal{I}^{-1}\)</span>).</p></li>
<li><p>A esta modificación del método de Newton se la conoce como <strong>Fisher Scoring</strong> y si bien ahora no lo vamos a usar, en <em>MLG</em> les van a preguntar si lo conocen (¡y esperamos que se acuerden que sí!).</p></li>
<li><p>Otras características que ahora puede que no entendamos pero que si volvemos a leer esto en el futuro tendrán más sentido, incluyen:</p>
<ul>
<li>La fórmula recursiva de Fisher Scoring se puede expresar como las ecuaciones normales de una regresión ponderada, por lo tanto a este procedimiento de ajuste también puede ser visto como un caso de <em>Mínimos Cuadrados Iterativamente Ponderados</em>.</li>
<li>Cuando en los <em>MLG</em> se usa algo que se llama <em>enlace canónico</em>, Fisher Scoring coincide exactamente con el método original de Newton.</li>
</ul></li>
</ul>


</section>
</section>
<aside id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>No es necesario, pero si querés recordar la diferencia entre funciones convexas y cóncavas, podés visitar <a href="https://www.universoformulas.com/matematicas/analisis/concavo-convexo/">este enlace</a>.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>No es necesario, pero si querés recordar qué son las matrices definidas o semidefinidas positivas o negativas podés visitar <a href="https://es.wikipedia.org/wiki/Matriz_definida_positiva">este enlace</a>.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</aside>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    const typesetMath = (el) => {
      if (window.MathJax) {
        // MathJax Typeset
        window.MathJax.typeset([el]);
      } else if (window.katex) {
        // KaTeX Render
        var mathElements = el.getElementsByClassName("math");
        var macros = [];
        for (var i = 0; i < mathElements.length; i++) {
          var texText = mathElements[i].firstChild;
          if (mathElements[i].tagName == "SPAN") {
            window.katex.render(texText.data, mathElements[i], {
              displayMode: mathElements[i].classList.contains('display'),
              throwOnError: false,
              macros: macros,
              fleqn: false
            });
          }
        }
      }
    }
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        for (let i = 0; i < 2; i++) {
          container.appendChild(note.children[i].cloneNode(true));
        }
        typesetMath(container);
        return container.innerHTML
      } else {
        typesetMath(note);
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      typesetMath(note);
      return note.innerHTML;
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./03_sistemas_lineales.html" class="pagination-link  aria-label=" &lt;span="" de="" sistemas="" ecuaciones="" lineales&lt;="" span&gt;"="">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Resolución de sistemas de ecuaciones lineales</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./05_autovalores.html" class="pagination-link" aria-label="<span class='chapter-number'>5</span>&nbsp; <span class='chapter-title'>Valores y vectores propios</span>">
        <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Valores y vectores propios</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>